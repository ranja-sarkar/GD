



![00](https://github.com/user-attachments/assets/8964b521-1dba-443e-a0e2-4b64d1bd7333)


Unlike predictive ML models where there’s a target and predictions are validated against test data, there’s no ground truth or target in causal models. Validating the robustness of causal models is the bottleneck.

**We can never observe both potential outcomes but only the one that actually occurs in causal models.**

# References

1. https://developers.google.com/meridian/docs/causal-inference/about-mmm-causal-inference-methodology

2. https://github.com/py-why/dowhy

